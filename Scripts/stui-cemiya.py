# Descripci贸n: Aplicaci贸n para detectar odio, violencia, lenguaje ofensivo o contenido inapropiado en un v铆deo.
# La aplicaci贸n divide el v铆deo en escenas y transcribe el audio de cada escena.

import streamlit as st
#from utilities.icon import page_icon
import scenedetect
import os
from ast import literal_eval
import requests
import json
import datetime
from openai import OpenAI
import base64
import pandas as pd
import io
from urllib.parse import urlparse
import subprocess

# global variables
url_qwen = 'http://155.210.153.36:8000/v1'
model = 'Qwen/Qwen2.5-VL-7B-Instruct'
url_whisper = 'http://gtc2pc9.cps.unizar.es:8000/transcribediarize'
archivo_audio = 'grabacion.wav' 
parametros = {
   'language': 'es',
   'model_size': 'large-v3',
   'word_timestamps': 'true'
}
supportedLanguages = ['es', 'en', 'ca', 'zh', 'de', 'ru', 'ko', 'fr', 'ja', 'pt', 'tr', 'pl', 'nl', 'ar', 'sv', 'it',
                      'id', 'hi', 'fi', 'vi', 'he', 'uk', 'el', 'ms', 'cs', 'ro', 'da', 'hu', 'ta', 'no', 'th', 'ur', 'hr',
                      'bg', 'lt', 'la', 'mi', 'ml', 'cy', 'sk', 'te', 'fa', 'lv', 'bn', 'sr', 'az', 'sl', 'kn', 'et', 'mk',
                      'br', 'eu', 'is', 'hy', 'ne', 'mn', 'bs', 'kk', 'sq', 'sw', 'gl', 'mr', 'pa', 'si', 'km', 'sn', 'yo',
                      'so', 'af', 'oc', 'ka', 'be', 'tg', 'sd', 'gu', 'am', 'yi', 'lo', 'uz', 'fo', 'ht', 'ps', 'tk', 'nn',
                      'mt', 'sa', 'lb', 'my', 'bo', 'tl', 'mg', 'as', 'tt', 'haw', 'ln', 'ha', 'ba', 'jv', 'su']

terminos_base="""Violencia f铆sica, LGBTQ+fobia (homofobia, transfobia, bifobia),\
Machismo (sexismo, misoginia), Racismo y xenofobia, Antigitanismo, Islamofobia, Antisemitismo, Aspectismo.
Cualquier sospecha de que el v铆deo o el audio tiene unos de estos t茅rminos ind铆calo en la descripci贸n y clasif铆calo de acuerdo al t茅rmino detectado.
"""

# Function to convert a dictionary to a XLSX data format
def dict_to_excel(data: dict, key_column_name: str = 'Key', sheet_name: str = 'Sheet1', engine: str = 'openpyxl') -> bytes:
    """
    Transforms a dictionary structure into an Excel file and returns the Excel data as bytes.

    Args:
        data (dict): The dictionary to transform.
        key_column_name (str, optional): The column name for keys of input dict. Defaults to 'Key'.
        sheet_name (str, optional):  Name of the Excel sheet. Defaults to 'Sheet1'.
        engine (str, optional):  The Excel writer engine to use. Defaults to 'openpyxl'. 'xlsxwriter' is another option.
                                Make sure the engine is installed (`pip install openpyxl` or `pip install xlsxwriter`).

    Returns:
        bytes: The Excel data as bytes.

    Raises:
        TypeError: If the input 'data' is not a dictionary.
        ValueError: If the 'data' dictionary is empty.
        ImportError: If the specified engine ('openpyxl' or 'xlsxwriter') is not installed.
    """

    if not isinstance(data, dict):
        raise TypeError("Input 'data' must be a dictionary.")
    if not isinstance(sheet_name, str):
        raise TypeError("Input 'sheet_name' must be a string")
    if not data:
        raise ValueError("Input 'data' dictionary cannot be empty.")

    try:
        # Case 1: Dictionary where values are dictionaries (convert to DataFrame easily)
        if all(isinstance(value, dict) for value in data.values()):
            df = pd.DataFrame.from_dict(data, orient='index')
            df.index.name = key_column_name

        # Case 2: Dictionary where values are lists of dictionaries (more complex)
        elif all(isinstance(value, list) and all(isinstance(item, dict) for item in value) for value in data.values()):
            rows = []
            for key, value_list in data.items():
                for item in value_list:
                    row = {key_column_name: key, **item}
                    rows.append(row)
            df = pd.DataFrame(rows)

        # Case 3: Dictionary where values are simple values (convert to series)
        elif all(not isinstance(value, (dict, list)) for value in data.values()):
            series = pd.Series(data)
            df = series.to_frame(name='Value')
            df.index.name = key_column_name


        else:
            raise ValueError("Unsupported dictionary structure. Values must be all dictionaries, lists of dictionaries, or simple values.")


        excel_buffer = io.BytesIO()  # Create an in-memory bytes buffer

        with pd.ExcelWriter(excel_buffer, engine=engine) as writer:
            df.to_excel(writer, sheet_name=sheet_name, index=False if (all(isinstance(value, list) and all(isinstance(item, dict) for item in value) for value in data.values())) else True )  #index False only for case 2

        excel_data = excel_buffer.getvalue()  # Get the Excel data as bytes
        return excel_data

    except ImportError as e:
        print(f"Error: The '{engine}' engine is not installed. Please install it (e.g., 'pip install openpyxl').")
        raise

    except Exception as e:
        print(f"Error converting dictionary to Excel data: {e}")
        raise

# Function to convert a dictionary to a CSV file

def dict_to_csv(data: dict, key_column_name: str = 'Key'):
    """
    Transforms a dictionary structure into a Pandas DataFrame and then saves it as a CSV file.

    Args:
        data (dict): The dictionary to transform. The keys of the dictionary will become the index or a column
                     depending on the structure of the values, and the values will become the columns or data rows.
                     The values can be dictionaries or lists of dictionaries.
        key_column_name (str, optional): If the dictionary values are dictionaries, this parameter determines
                                       the column name to use for the keys of the input dictionary. Defaults to 'Key'.

    Raises:
        TypeError: If the input 'data' is not a dictionary or 'csv_filepath' is not a string.
        ValueError: If the 'data' dictionary is empty.
    """

    if not isinstance(data, dict):
        raise TypeError("Input 'data' must be a dictionary.")
    if not data:
        raise ValueError("Input 'data' dictionary cannot be empty.")

    try:
        # Case 1: Dictionary where values are dictionaries (convert to DataFrame easily)
        if all(isinstance(value, dict) for value in data.values()):
            df = pd.DataFrame.from_dict(data, orient='index')
            df.index.name = key_column_name
            csv_output = df.to_csv(index=True,sep=";",encoding='utf-8')

        # Case 2: Dictionary where values are lists of dictionaries (more complex)
        elif all(isinstance(value, list) and all(isinstance(item, dict) for item in value) for value in data.values()):
            rows = []
            for key, value_list in data.items():
                for item in value_list:
                    row = {key_column_name: key, **item}  # Combine key and item dictionary
                    rows.append(row)
            df = pd.DataFrame(rows)
            csv_output = df.to_csv(index=False,sep=";",encoding='utf-8')  # No index in this case

        # Case 3: Dictionary where values are simple values (convert to series)
        elif all(not isinstance(value, (dict, list)) for value in data.values()):
            series = pd.Series(data)
            df = series.to_frame(name='Value')  # Convert series to a DataFrame
            df.index.name = key_column_name
            csv_output = df.to_csv(index=True,sep=";",encoding='utf-8')

        else:
            raise ValueError("Unsupported dictionary structure. Values must be all dictionaries, lists of dictionaries, or simple values.")

        print(f"Successfully converted dictionary to CSV")
        return csv_output

    except Exception as e:
        print(f"Error converting dictionary to CSV: {e}")
        raise


# encode in base64 a mp4 file from a local file

def encode_base64_mp4_from_localfile(content_url: str) -> str:
    """Encode a content retrieved from a remote url to base64 format."""
    with open(content_url, "rb") as f:
        result = "data:video/base64,"+base64.b64encode(f.read()).decode('utf-8')
    return result

# split the video into scenes

def split_video(video_path,scene_path):
    # Create a VideoManager object and perform scene detection
    video_manager = scenedetect.VideoManager([video_path])
    scene_manager = scenedetect.SceneManager()
    scene_manager.add_detector(scenedetect.detectors.AdaptiveDetector())
    base_timecode = video_manager.get_base_timecode()

    video_manager.set_downscale_factor()
    video_manager.start()

    # Perform scene detection on the video file
    total_frames=scene_manager.detect_scenes(frame_source=video_manager)

    # Obtain the list of detected scenes
    scene_list = scene_manager.get_scene_list(base_timecode,start_in_scene=True)
    

    print(scene_list)
    print(scene_path)
    if len(scene_list) == 0:
        
        print("No scenes detected.")
        print("Duration:", total_frames/video_manager.get_framerate())
        # video duration in timecode datetime.timedelta(seconds=segment['start'])
        video_duration = datetime.timedelta(seconds=total_frames/video_manager.get_framerate())
        print(video_duration)
        # todo el video es una escena
        scene_list = None
    else:
            # Remove scenes with less than 1 second
        scene_list = [scene for scene in scene_list if scene[1].get_frames() - scene[0].get_frames() > video_manager.get_framerate()]
        print("List of scenes obtained:")
        for i, scene in enumerate(scene_list):
            print(
                "    Scene %2d: Start %s / Frame %d, End %s / Frame %d"
                % (
                    i + 1,
                    scene[0].get_timecode(),
                    scene[0].get_frames(),
                    scene[1].get_timecode(),
                    scene[1].get_frames(),
                )
            )

    # save the scene videos to a file

    if scene_list:
        scenedetect.video_splitter.split_video_ffmpeg(video_path, scene_list, output_dir="escenas")
    else:
        # save the video to the scenes folder
        scene_video = f"escenas/{scene_path}-Scene-001.mp4"
        os.rename(video_path, scene_video)
        scene_list = [(base_timecode, video_duration)]
    video_manager.release()
    return scene_list



st.set_page_config(
    page_title="Cemiya Project",
    page_icon="",
    layout="wide",
    initial_sidebar_state="expanded",
)
def clear_text():
    st.session_state.image_url = ""
    st.session_state.video = False

@st.cache_resource
def qwen_client():
    return OpenAI(
        base_url=url_qwen,
        api_key="EMPTY",
    )   

def get_description(model, client, messages):

#print("Chat completion input:", message)
## Use video url in the payload
    chat_completion_from_url = client.chat.completions.create(
        messages=messages,
        model=model,
        max_completion_tokens=1024,
    )

    result = chat_completion_from_url.choices[0].message.content
       
    try:
        output=literal_eval(result)
    except:
        output=result
    return output


def transcribe_video(video_path):
    global archivo_audio
    archivo_audio = f"temp_audio_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}.wav"
    transcripcion=[]
    print(video_path)
# extract the audio from the video
    command = [
        "ffmpeg",
        "-i",
        video_path,
        "-y",
        "-vn",
        "-acodec",
        "pcm_s16le",
        "-ar",
        "16000",
        "-ac",
        "2",
        archivo_audio
    ]

    try:
        result = subprocess.run(command, capture_output=True, text=True, check=True) # check=True lanza excepci贸n si error
        print("Salida de ffmpeg:", result.stdout)
        print("Error de ffmpeg:", result.stderr)  # Imprime los errores tambi茅n
        print("Conversi贸n exitosa.")
        # systemcall=f"ffmpeg -i {video_path} -y -vn -acodec pcm_s16le -ar 16000 -ac 2 {archivo_audio}"
        # os.system(systemcall)
        files = {'audio_data': open(archivo_audio, 'rb')}
        # Realizar la llamada POST con requests
        respuesta = requests.post(url_whisper, files=files, data=parametros)
        print(respuesta.text)
        # Remove the temporary audio file
        if os.path.exists(archivo_audio):
            os.remove(archivo_audio)
        out=json.loads(respuesta.text)    
        for segment in out['segments']:
            # cambia el formato de tiempo de segundos a HH:MM:SS.mmm
            x=datetime.timedelta(seconds=segment['start'])
            # comprobar si lleva milisegundos
            if '.' in str(x):
                segment['start']=str(x)  
            else:
                segment['start']=str(x)+'.000'
            x=datetime.timedelta(seconds=segment['end'])
            if '.' in str(x):
                segment['end']=str(x)  
            else:           
                segment['end']=str(x)+'.000'
        
            # si existe el campo speaker
            if 'speaker' in segment:
                transcripcion.append([segment['start'], segment['end'], '<S#'+segment['speaker'].replace("SPEAKER_","")+">",segment['text']])
            else:
                transcripcion.append([segment['start'], segment['end'],'<S#>',segment['text']])
    except subprocess.CalledProcessError as e:
        print(f"Error al ejecutar ffmpeg: {e}")
        print("Salida de ffmpeg (error):", e.stderr)
        # Manejar el error (mostrar mensaje, registrar, etc.)
        transcripcion=""

    if len(transcripcion)==0:
        transcripcion=[['00:00:00.000', '00:00:00.000', '<S#0>', "No se ha detectado ninguna voz en la grabaci贸n"]]
    # cambiar el formato de la transcripci贸n a JSON
    json_transcripcion={}
    for i,segment in enumerate(transcripcion):
        json_transcripcion[i]={
            "start": segment[0],
            "end": segment[1],
            "speaker": segment[2],
            "text": segment[3]
        }
    return json_transcripcion

def display_transcripcion(transcripcion):
    texto=""
    if transcripcion is not None:
        for i,segment in transcripcion.items():
            texto+=f"<strong>{i+1} </strong>{segment['start']} -- {segment['end']} {segment['speaker']}: {segment['text']}<br>"
        st.markdown(texto, unsafe_allow_html=True)



def get_scene_transcription(transcription,tiempo_inicio,tiempo_fin):
    transcripcion=[]
    tini=datetime.datetime.strptime(tiempo_inicio, '%H:%M:%S.%f')
    tfin=datetime.datetime.strptime(tiempo_fin, '%H:%M:%S.%f')
    for i,segment in transcription.items():
        segini=datetime.datetime.strptime(segment['start'], '%H:%M:%S.%f')
        segfin=datetime.datetime.strptime(segment['end'], '%H:%M:%S.%f')
        if segini<=tini and segfin>=tini:
            transcripcion.append([segment['start'], segment['end'], segment['speaker'], segment['text']])
        if segini>=tini and segfin<=tfin:
            transcripcion.append([segment['start'], segment['end'], segment['speaker'], segment['text']])
    if len(transcripcion)==0:
        transcripcion=[tiempo_inicio, tiempo_fin, '<S#0>', "No se ha detectado ninguna voz en la grabaci贸n"]
    return str(transcripcion)
        
def get_speakerandtexto(transcription):
    print("get_speakerandtexto")
    print(transcription)
    print(type(transcription))
    transcrip=[]
    if len(transcription)>0:
        for segment in literal_eval(transcription):
            print(segment)
            transcrip.append([segment[2],segment[3]])
    else:
        transcrip=['<S#>', "No se ha detectado ninguna voz en la grabaci贸n"]
    return str(transcrip)

def promptfijo(transcripcion_escena, historia):
    texto=f"""
    Eres un modelo de lenguaje visual especializado en identificar contenido que pueda reflejar o promover formas de discriminaci贸n y 
    odio en las im谩genes, v铆deos y transcripciones de audio.

    La transcripci贸n del audio del plano de montaje que vamos a analizar es la siguiente: {transcripcion_escena}.

    El formato de la transcripci贸n es json donde 'start' y 'end' son los tiempos de inicio y fin de la transcripci贸n, 'speaker' 
    es el identificador del hablante y 'texto' es la transcripci贸n del hablante.
    """    
    # Adem谩s, en los planos de montaje anteriores has justificado tu decisi贸n en los siguientes hechos: 
    
    # {historia}.
    
    # Ay煤date de esta informaci贸n para los casos en los que para el plano que est谩s analizando no queda claro si hay alguna forma de discriminaci贸n u 贸dio.
    # Si el an谩lisis del plano actual es clara la forma de discriminaci贸n u odio, ya sea en el v铆deo o en el audio o en ambos, puedes tomar la decisi贸n directamente sin utilizar los hechos anteriores.

    return texto

def prompteditable():

    texto="""

    La definici贸n de las formas de discriminaci贸n y odio son las siguiente:
    
    Violencia f铆sica: Actos de agresi贸n f铆sica, amenazas de violencia, im谩genes de lesiones o da帽os f铆sicos, o contenido que glorifique la violencia.

    LGBTQ+fobia (Homofobia, Transfobia, Bifobia): Contenido que denigre, insulte, discrimine o promueva prejuicios contra personas lesbianas, gays, bisexuales, transg茅nero o de otras identidades de g茅nero y orientaciones sexuales. Incluye discursos de odio, insultos, negaci贸n de derechos y promoci贸n de la violencia contra personas LGBTQ+.

    Machismo (Sexismo, Misoginia): Contenido que perpet煤a estereotipos de g茅nero da帽inos, discrimina o deval煤a a las mujeres, o promueve la superioridad masculina. Incluye insultos sexistas, objetificaci贸n, acoso, y la promoci贸n de la violencia contra las mujeres.

    Racismo y Xenofobia: Contenido que discrimina, insulta o promueve prejuicios contra personas por su raza, origen 茅tnico, nacionalidad o ascendencia. Incluye estereotipos raciales, insultos racistas, la promoci贸n de la discriminaci贸n y la incitaci贸n al odio racial.

    Antigitanismo: Contenido que discrimina, insulta o promueve prejuicios contra el pueblo gitano. Incluye estereotipos negativos, insultos, la negaci贸n de sus derechos y la promoci贸n de la exclusi贸n social.

    Islamofobia: Contenido que discrimina, insulta o promueve prejuicios contra personas musulmanas o contra el Islam en general. Incluye estereotipos negativos, insultos, la promoci贸n del odio y la justificaci贸n de la discriminaci贸n.

    Antisemitismo: Contenido que discrimina, insulta o promueve prejuicios contra personas jud铆as. Incluye estereotipos negativos, insultos, la negaci贸n del Holocausto, teor铆as de conspiraci贸n y la promoci贸n del odio.

    Aspectismo: prejuicio o discriminaci贸n hacia las personas que se consideran f铆sicamente poco atractivas.
    

    Utiliza siempre el siguiente formato para tu respuesta:

    {
    "justificacion": "texto con la justificaci贸n.",
    "clasificacion": "Clasificaci贸n del v铆deo seg煤n las categor铆as definidas."
    }
    
    Si tienes que escribir comillas dobles en tu respuesta, utiliza siempre comillas simples para delimitar la cadena de texto.
    Recuerda en la descripci贸n de la escena utiliza simpre comillas simples, nunca comillas dobles. Est谩 prohibido el uso de comillas dobles en la descripci贸n de la escena.
    En ning煤n caso utilices comillas dobles en la descripci贸n de la escena.
    Indicar si se detecta en las im谩genes o en el audio odio, violencia, lenguaje ofensivo o contenido inapropiado.
    Proporciona la descripci贸n de la escena con detalle pero escribe solo en espa帽ol.

    ###Instrucciones para realizar el an谩lisis:

    An谩lisis Contextual: Eval煤a la imagen en su contexto completo. Considera el texto que la acompa帽a, la fuente de la imagen, el prop贸sito aparente de la comunicaci贸n y la descripci贸n de los planos anteriores.

    Identificaci贸n de Indicadores: Busca indicadores visuales y textuales que puedan sugerir la presencia de alguna de las formas de discriminaci贸n y odio mencionadas. Ten encuenta los indicadores previos.

    Priorizar la Intenci贸n: Intenta determinar la intenci贸n del creador del contenido. 驴Est谩 tratando de promover el odio o la discriminaci贸n, o est谩 simplemente informando sobre un problema o expresando una opini贸n controversial?

    Evitar Falsos Positivos: S茅 cauteloso al identificar contenido como discriminatorio u odioso. Aseg煤rate de que haya evidencia clara y convincente antes de hacer una clasificaci贸n.

    Sensibilidad Cultural: Ten en cuenta las diferencias culturales y las posibles interpretaciones err贸neas del contenido.

    Manejo de la Ambig眉edad: Si no est谩s seguro de si una imagen es discriminatoria u odiosa, clasif铆cala como "incierta" o "necesita revisi贸n humana".

    Sesgos: Presta especial atenci贸n a los sesgos que puedes tener.

    Clasificaci贸n: Clasifica en una o m谩s de las siguientes categor铆as:

        Violencia F铆sica

        LGBTQ+fobia

        Machismo

        Racismo y Xenofobia

        Antigitanismo

        Islamofobia

        Antisemitismo

        Aspectismo

        Incerteza/Necesita Revisi贸n Humana

        No contiene contenido inapropiado

    ###Ejemplo de Salida:
    {
    'clasificacion': 'Racismo y Xenofobia, Machismo',
    'justificacion': 'El video muestra [descripci贸n del v铆deo y transcripci贸n de audio] y contiene elementos que perpet煤an estereotipos raciales y sexistas al 
    [explicaci贸n de c贸mo se perpet煤an los estereotipos]'.
     """
    return texto

def prompt_history(history):
    texto=f"""
    Esta es la justificaci贸n de los dos planos anteriores:
    {history}
    
    Utiliza esta informaci贸n para tomar una decisi贸n en el plano actual.
    """
    return texto


def prompt(transcription_escena,terminos,tiempo_inicio="00:00:00",tiempo_fin="00:00:00"):
# Prompt text
# La transcripci贸n del audio del v铆deo completo es la siguiente: """+transcription+""" 
    texto ="""La siguiente secuencia de frames se corresponde con una escena de un v铆deo que empieza en el tiempo """+tiempo_inicio+""" 
    y termina en el tiempo """+tiempo_fin+""".<br>
    Tu funci贸n es clasificar la escena en t茅rminos de si contiene contenido inapropiado.<br>
    Se trata de detectar si en el v铆deo o en la transcripci贸n del audio hay indicios de <strong>"""+terminos+"""</strong>.<br>
    Escribe solo en espa帽ol.<br>
    Recuerda que la descripci贸n de la escena debe ser objetiva y precisa y en t茅rminos de detectar si hay <strong>"""+terminos+"""</strong>.<br>
    La transcripci贸n del audio de la escena es la siguiente: """+transcription_escena+""".<br>
    El formato de la transcripci贸n es json donde 'start' y 'end' son los tiempos de inicio y fin de la transcripci贸n, 'speaker' 
    es el identificador del hablante y 'texto' es la transcripci贸n del hablante.<br>
    Utiliza el siguiente formato para tu respuesta:<br>
    {
    "justificacion": "Descripci贸n de la escena en terminos de si hay <strong>"""+terminos+"""</strong>",
    "clasificacion": "Clase de la escena: """+terminos+""" o no contiene contenido inapropiado."
    }
    Si tienes que escribir comillas dobles en tu respuesta, utiliza siempre comillas simples para delimitar la cadena de texto.
    Recuerda en la descripci贸n de la escena utiliza simpre comillas simples, nunca comillas dobles. Est谩 prohibido el uso de comillas dobles en la descripci贸n de la escena.
    En ning煤n caso utilices comillas dobles en la descripci贸n de la escena.
    Indicar si se detecta en las im谩genes o en el audio odio, violencia, lenguaje ofensivo o contenido inapropiado.
    Proporciona la descripci贸n de la escena con detalle pero escribe solo en espa帽ol.
    
    """
    return texto

def clear_all():
    st.session_state.uploaded_file_state = None
    st.session_state.video_url = ""
    st.session_state.description = ""
    st.session_state.transcripcion = None
    st.session_state.scene_list = {}
    st.session_state.scene_description = {}
    st.session_state.scenes = {}
    st.session_state.instrucciones= prompteditable()
    st.session_state.historia=[]

def visualizar_escena(scene,i,scenefilename):
    if 'no contiene contenido inapropiado' in scene['clasificacion'].lower():
        icon = ""
    else:
        icon = ""
    with st.expander(f"Plano {i+1}: {scene['clasificacion']}",icon=icon):
        scol1, scol2 = st.columns([0.3, 0.7])
        with scol1:
            try:
                st.video(scenefilename,format="video/mp4")
            except:
                st.write('short video')
        with scol2:
            text=""
            for key in scene.keys():
                if key != "transcripcion":
                    text+=f"<strong>{key}:</strong> {scene[key]}<br>"
            st.markdown(text, unsafe_allow_html=True)
        st.write("Transcripci贸n de la escena")
        st.write(scene['transcripcion'])    

def visualizar_escenas(scenes,filename):
    """
    Visualiza las escenas detectadas en el v铆deo.
    Utiliza el m茅todo st.expander para mostrar cada escena detectada.
    presentando el tiempo de inicio y fin de
    cada escena, la descripci贸n de la escena y la transcripci贸n del audio de la
    escena.
    muestra el v铆deo de la escena.
    Args:
        scenes (dict): Diccionario con las escenas detectadas en el v铆deo.
    
    Returns:
        None

    """
    for i, scene in scenes.items():
        scenefilename=f"escenas/{filename}-Scene-{i+1:03d}.mp4" 
        visualizar_escena(scene,i,scenefilename)

def obtener_nombre_archivo_de_url(url):
    """
    Extrae el nombre del archivo de una URL.

    Args:
        url: La URL del archivo.

    Returns:
        El nombre del archivo, o None si no se puede extraer.
    """
    try:
        # Analizar la URL usando urllib.parse
        parsed_url = urlparse(url)

        # Obtener la ruta de la URL
        path = parsed_url.path

        # Extraer el nombre del archivo de la ruta usando os.path.basename
        nombre_archivo = os.path.basename(path)

        # Si el nombre del archivo est谩 vac铆o (por ejemplo, la URL termina en /),
        # intenta obtenerlo de los headers Content-Disposition (si est谩n presentes)
        if not nombre_archivo:
            respuesta = requests.head(url)  # Usar HEAD para no descargar el contenido
            respuesta.raise_for_status()

            content_disposition = respuesta.headers.get("Content-Disposition")
            if content_disposition:
                # Buscar el nombre del archivo en el header Content-Disposition
                for part in content_disposition.split(";"):
                    part = part.strip()
                    if part.startswith("filename="):
                        nombre_archivo = part.split("=", 1)[1].strip('"') # remover quotes do nome do arquivo se houver
                        break

        # Devolver el nombre del archivo
        return nombre_archivo

    except requests.exceptions.RequestException:
        print("Error al obtener las cabeceras de la URL.")
        return None
    except Exception as e:
        print(f"Error al extraer el nombre del archivo: {e}")
        return None
    
def descargar_video(url, nombre_archivo):
  """
  Descarga un video MP4 desde una URL y lo guarda en un archivo local.

  Args:
    url: La URL del video MP4.
    nombre_archivo: El nombre del archivo donde se guardar谩 el video.
  """

  try:
    # Realizar una petici贸n GET a la URL del video con streaming
    respuesta = requests.get(url, stream=True)

    # Verificar si la petici贸n fue exitosa (c贸digo 200)
    respuesta.raise_for_status()  # Lanza una excepci贸n en caso de error

    # Abrir el archivo en modo binario para escritura
    with open(nombre_archivo, 'wb') as archivo:
      # Iterar sobre los chunks de la respuesta y escribirlos en el archivo
      for chunk in respuesta.iter_content(chunk_size=8192):  # 8KB por chunk
        if chunk:  # Filtrar chunks vac铆os
          archivo.write(chunk)

    print(f"Video descargado exitosamente a: {nombre_archivo}")

  except requests.exceptions.RequestException as e:
    print(f"Error al descargar el video: {e}")
  except Exception as e:
    print(f"Ocurri贸 un error inesperado: {e}")

def procesar_audio(videofilename):
    with st.spinner("Transcribiendo el v铆deo ..."):
        transcripcion_video=transcribe_video(videofilename)
        st.session_state.transcripcion=transcripcion_video
    # descargamos la transcripci贸n del video en formato csv 

def main():


    st.markdown("""
        <style>
               .block-container {
                    padding-top: 3rem;
                    padding-bottom: 0rem;
                    padding-left: 5rem;
                    padding-right: 5rem;
                }
        </style>
        """, unsafe_allow_html=True)
    
    if os.path.exists("Cabecera_Cemiya.jpg"):
        st.image("Cabecera_Cemiya.jpg", width=400)
    else:
        st.warning("Imagen 'Cabecera_Cemiya.jpg' no encontrada. Verifica que est茅 en la carpeta del proyecto.")

    with st.sidebar:
        st.image("MICIUCofinanciadoAEI-768x149.jpg",width=400)
        with st.expander("Informaci贸n de uso"):
            st.markdown("""
                    ## Configuraci贸n del sistema de an谩lisis:

                    1.  Se puede seleccionar el idioma del audio y el modelo de transcripci贸n a utilizar.
                    2.  Se puede seleccionar el modelo de lenguaje visual a utilizar.
                    3.  Se puede particularizar las instrucciones para el an谩lisis del v铆deo.

                    ## Funcionamiento:

                    1.  Cargar un video con "Browse file" o escribiendo la url donde se encuentra el video mp4.
                    2.  Comprobar que las instrucciones son las correctas para la tarea. ##No modificar el formato de salida.## Se puede modificar las categorias y su descripci贸n. Para que se actualizar terminar con Ctrl+Enter.
                    2.  Una vez cargado se puede:
                        *   2.a. Transcribir el audio pulsando el bot贸n "transcribir el v铆deo" que aparece debajo del contenedor de visualizaci贸n del v铆deo.
                        *   2.b. Dividir el v铆deo es planos de montaje pulsando el bot贸n "Detectar planos de montaje".
                    3.  Una vez dividido el v铆deo en planos de montaje se puede analizar pulsando el bot贸n "Analizar v铆deo por planos".

                    Tanto la transcripci贸n como el an谩lisis por planos se puede descargar en formato excel pulsando el respectivo bot贸n.
                     """)
        with st.container(border=True):
            st.write("Configuraci贸n audio")
            parametros['language'] = st.selectbox('Selecciona el idioma ', supportedLanguages,index=0)
            st.markdown("""---""")
            parametros['model_size'] = st.selectbox('Selecciona el tama帽o del modelo (def: large-v3)', ['small', 'medium', 'large-v3'], index=2)
        with st.container(border=True):
            st.write("Configuraci贸n modelo de lenguaje")
            vlmodel = st.selectbox('Selecciona el modelo', ['Qwen/Qwen2.5-VL-7B-Instruct','Qwen/Qwen2.5-VL-3B-Instruct'], index=0)
        # with st.container(border=True):
        #     st.write("T茅rminos a detectar")
        #     terminos = st.text_area("Escribe los t茅rminos a detectar en el v铆deo", terminos_base,height=200)


    if "file_uploader" not in st.session_state:
        st.session_state.uploaded_file_state = None
    if "video_url" not in st.session_state:
        st.session_state.image_url = ""
    if "description" not in st.session_state:
        st.session_state.description = ""
    if "transcripcion" not in st.session_state:
        st.session_state.transcripcion = None
    if "scene_list" not in st.session_state:
        st.session_state.scene_list = {}
    if "scene_description" not in st.session_state:
        st.session_state.scene_description = {}
    if "scenes" not in st.session_state:
        st.session_state.scenes = {}
    if "instrucciones" not in st.session_state:
        st.session_state.instrucciones= prompteditable()
    if "historia" not in st.session_state:
        st.session_state.historia=[]
        
    # Load the model and processor
#    model, processor = load_qwenmodel()
    client = qwen_client()
    videourl = None
    scene_list={}
    scenes=None
    scene_description=None
    transcripcion_video=None
    instrucciones=st.session_state.instrucciones

    if not os.path.exists("videos"):
        os.mkdir("videos")
        
    if not os.path.exists("escenas"):
        os.mkdir("escenas")
        
    col_1, col_2 = st.columns([0.7,0.3])
    with col_1.container():
        uploaded_file = st.file_uploader(
            "Sube un v铆deo para analizar", type=["mp4"], key="file_uploader",on_change=clear_all
        )
        st.text_input("O pega aqu铆 la url del v铆deo", key="video_url")#,on_change=clear_text)
        videourl = st.session_state.video_url
        with st.expander("Instrucciones"):
            instrucciones=st.text_area(" ",st.session_state.instrucciones,height=65*10)
            st.session_state.instrucciones=instrucciones
#        st.expander("Instrucciones").markdown(prompt('Aqu铆 va la transcrici贸n de la escena',terminos,"00:00:00","00:00:00"),unsafe_allow_html=True)
        
    with col_2.container(border=True):
        if uploaded_file is not None:
            st.session_state.uploaded_file_state = uploaded_file.getvalue()
            # get file name extension from uploaded file
            ext = uploaded_file.name.split(".")[-1]
            filename=uploaded_file.name
            filename=filename.split(".")[0]
            videofilename="videos/"+filename+".mp4"
            # transcribe the video

            if ext in ["mp4"]:
                st.video(uploaded_file,format="video/mp4")
            
                # save the video to a file
                with open(videofilename, "wb") as f:
                    f.write(uploaded_file.getvalue())                

        if videourl:
            filename=obtener_nombre_archivo_de_url(videourl)
            videofilename="videos/"+filename+".mp4"
            # transcribe the video            
            st.video(videourl,format="video/mp4")
            descargar_video(videourl,videofilename)
            
       
        
    col1,col2=st.columns(2)
    if uploaded_file is not None or videourl:   
        with col1.container(border=True):
            col11,col12=st.columns(2)
            with col11:
                if st.button("1. Transcribir el v铆deo",type="primary",icon=":material/transcribe:"):
                    procesar_audio(videofilename)
            with col12:
                if st.session_state.transcripcion:
            
                    transcriptionfilename=filename+"-transcripcion.xlsx"
                    st.download_button(
                        "Descargar transcripci贸n del v铆deo",
                        dict_to_excel(st.session_state.transcripcion),
                        file_name=transcriptionfilename,
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        type="primary",
                        icon=":material/download:",
                    )
                    
            with st.expander("Transcripci贸n del video"):
                display_transcripcion(st.session_state.transcripcion)  
            # scene detection
    
        with col2.container(border=True):

            if st.button("2. Detectar planos de montaje",type="primary",icon=":material/scene:"):
                with st.spinner("Detectando planos ..."):
                    scene_list = split_video(videofilename,filename)
                    st.session_state.scene_list = scene_list
            st.write("N煤mero de planos de montaje detectados:", len(st.session_state.scene_list))

    if st.session_state.scene_list:
        with st.container(border=True):
            col3,col4=st.columns(2)
            with col3:
                if st.session_state.scene_list and st.button("3. Analizar v铆deo por planos",type="primary",icon=":material/analytics:"):
                    if not st.session_state.transcripcion:
                        st.write("Se analizar谩 el v铆deo sin transcripci贸n")
                        
                    st.session_state.scene_description={}
                    for i, scene in enumerate(st.session_state.scene_list):     
                        # get the scene video from the scenes folder. The scene number has 3 digits
                        scene_video = f"escenas/{filename}-Scene-{i+1:03d}.mp4"  
                        print(scene_video)      

                        # check if the scene video exists
                        if os.path.exists(scene_video):
                            # transcribe the video
        #                        transcription=get_speakerandtexto(transcribe_video(scene_video))
        #                        print(transcription)
                            if st.session_state.transcripcion:
                                transcription=get_scene_transcription(st.session_state.transcripcion,scene[0].get_timecode(),scene[1].get_timecode())
                            else:
                                transcription="No se ha detectado ninguna voz en la grabaci贸n"
        #                        print(transcription) 
                            # get scene duration in frames
                            textoprompt=promptfijo(transcription, st.session_state.historia)+st.session_state.instrucciones
                            print("Prompt.........................")
                            print(promptfijo(transcription, st.session_state.historia))
                            print(".................................")
                            scene_duration = scene[1].get_frames() - scene[0].get_frames()
                            # establish the frame rate for the vllm model
                            if scene_duration < 3000:
                                fps=1
                            elif scene_duration < 4000:
                                fps=0.5
                            else:
                                fps=0.25
                            messages = [{
                                "role": "user",
                                "content": [
                                    {
                                        "type": "video_url",
                                        "video_url": 
                                            {
                                            'url': encode_base64_mp4_from_localfile(scene_video)
                                            },
                                        "max_pixels": 360 * 420,
                                        "fps": fps,
                                    },
                                    {"type": "text", "text": textoprompt},
#                                    {"type": "text", "text": prompt(transcription,terminos,scene[0].get_timecode(),scene[1].get_timecode())},
                                ],
                            }]  
                            print("scene duration: ", scene_duration, "fps: ",fps) 
                            with st.spinner(f"Analizando plano {i+1} ..."):                         
                                scene_description = get_description(vlmodel, client, messages)

                            print(scene_description)
                            print(type(scene_description))
                            try:
                                scene_description=json.loads(scene_description)
                            except:
#                                print("Error en el formato dict")
                                scene_description=scene_description
                            #
                            print(scene_description.keys())
                            st.session_state.scene_description[i]=scene_description
                            # create a dict with the scene description fields, timecodes and scene number
                            st.session_state.scenes[i] = {
                                "tiempo_inicio": scene[0].get_timecode(),
                                "tiempo_final": scene[1].get_timecode(),
                                "justificacion": scene_description['justificacion'],
                                "clasificacion": scene_description['clasificacion'],
                                "transcripcion": transcription
                            }
                            # display the scene numbre, timecodes and description.
                            visualizar_escena(st.session_state.scenes[i],i,scene_video)
                            st.session_state.historia.append(scene_description['justificacion'])
                            if len(st.session_state.historia)>2:
                                st.session_state.historia = st.session_state.historia[-2:]
                                                    


        #                            scenes[i+1] = {"description": scene_description, "start_time": scene[0].get_timecode(), "end_time": scene[1].get_timecode(), "transcription": transcription}

                        else:
                            st.write(f"Plano {i+1} not found")
                                            # guardar en un fichero json las escenas
                    st.rerun()
            with col4:
                if st.session_state.scenes:
                    # change scene description to csv format
                    scene_description={}
                    for i,scene in st.session_state.scenes.items():
                        scene_description[i]=scene

                    # filename for the csv file
                    descriptionfilename=filename+"-justificacion.xlsx"
                    st.download_button(
                        label="Descargar descripci贸n de los planos de montaje",
                        data=dict_to_excel(scene_description),
                        file_name=descriptionfilename,
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        type="primary",
                        icon=":material/download:",
                    )
                            # Comprobar si el directorio existe
                    if not os.path.exists("justificacion"):
                        # Si no existe, crear el directorio (y los directorios intermedios si es necesario)
                        os.makedirs("justificacion")
                        print(f"Directorio creado")

                    # Save scene description to an Excel file
                    scene_description_excel = dict_to_excel(scene_description)
                    with open(f"justificacion/{descriptionfilename}", "wb") as f:
                        f.write(scene_description_excel)

                    # visualizar las escenas
            visualizar_escenas(st.session_state.scenes,filename)

        # with open("scenes.json", "w") as f:
        #         json.dump(scenes, f)
    # else:    
    #     st.write("No se ha cargado ning煤n v铆deo ni se ha proporcionado ninguna URL")  
        

if __name__ == "__main__":
    main()



